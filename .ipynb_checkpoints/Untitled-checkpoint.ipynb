{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46cbd6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import gym\n",
    "import tensorflow_probability as tfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "906f3f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActorCritic(tf.keras.Model):\n",
    "    def __init__(self, action_dim):\n",
    "        super().__init__()\n",
    "        self.fc1 = tf.keras.layers.Dense(512, activation=\"relu\")\n",
    "        self.fc2 = tf.keras.layers.Dense(128, activation=\"relu\")\n",
    "        self.critic = tf.keras.layers.Dense(1, activation=None)\n",
    "        self.actor = tf.keras.layers.Dense(action_dim, activation=None)\n",
    "        \n",
    "    def call(self, input_data):\n",
    "        x = self.fc1(input_data)\n",
    "        x1 = self.fc2(x)\n",
    "        actor = self.actor(x1)\n",
    "        critic = self.critic(x1)\n",
    "        return actor, critic\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c11ed68",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, action_dim=4, gamma=0.99):\n",
    "        self.gamma = gamma \n",
    "        self.opt = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "        self.actor_critic = ActorCritic(action_dim)\n",
    "        \n",
    "    def get_action(self, state):\n",
    "        _, action_probs = self.actor_critic(np.array([state]))\n",
    "        action_probs = tf.nn.softmax(action_probs)\n",
    "        action_probs = action_probs.numpy()\n",
    "        dist = tfp.distributions.Categorical(\n",
    "            probs=action_probs, dtype=tf.float32\n",
    "        )\n",
    "        action = dist.sample()\n",
    "        return int(action.numpy()[0])\n",
    "    \n",
    "    def actor_loss(self, prob, action, td):\n",
    "        prob = tf.nn.softmax(prob)\n",
    "        dist = tfp.distributions.Categorical(probs=prob, dtype=tf.float32)\n",
    "        log_prob = dist.log_prob(action)\n",
    "        loss = -log_prob * td\n",
    "        return loss\n",
    "    \n",
    "    def learn(self, state, action, reward, next_state, done):\n",
    "        state = np.array([state])\n",
    "        next_state = np.array([next_state])\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            value, action_probs = self.actor_critic(state, training=True)\n",
    "            value_next_st, _ = self.actor_critic(next_state, training=True)\n",
    "            td = reward + self.gamma * value_next_st * (1 - int(done)) - value\n",
    "            actor_loss = self.actor_loss(action_probs, action, td)\n",
    "            critic_loss = td ** 2\n",
    "            total_loss = actor_loss + critic_loss\n",
    "        grads = tape.gradient(total_loss, self.actor_critic.trainable_variables)\n",
    "        self.opt.apply_gradients(zip(grads, self.actor_critic.trainable_variables))\n",
    "        return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "deadb162",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(agent, env, episodes, render=True):\n",
    "    \n",
    "    for episode in range(episodes):\n",
    "        \n",
    "        done = False\n",
    "        state = env.reset()\n",
    "        total_reward = 0\n",
    "        all_loss = []\n",
    "        \n",
    "        while not done:\n",
    "            action = agent.get_action(state)\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            loss = agent.learn(state, action, reward, next_state, done)\n",
    "            all_loss.append(loss)\n",
    "            state = next_state\n",
    "            total_reward += reward\n",
    "            if render: \n",
    "                env.render()\n",
    "            if done:\n",
    "                print(\"\\n\")\n",
    "            print(f\"Episode {episode}, ep_reward: {total_reward}\", end=\"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4067d84e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0, ep_reward: 9.0\n",
      "\n",
      "Episode 1, ep_reward: 9.00\n",
      "\n",
      "Episode 2, ep_reward: 8.00\n",
      "\n",
      "Episode 3, ep_reward: 8.0\n",
      "\n",
      "Episode 4, ep_reward: 9.0\n",
      "\n",
      "Episode 5, ep_reward: 9.00\n",
      "\n",
      "Episode 6, ep_reward: 9.00\n",
      "\n",
      "Episode 7, ep_reward: 8.00\n",
      "\n",
      "Episode 8, ep_reward: 7.0\n",
      "\n",
      "Episode 9, ep_reward: 7.0\n",
      "\n",
      "Episode 10, ep_reward: 8.0\n",
      "\n",
      "Episode 11, ep_reward: 8.0\n",
      "\n",
      "Episode 12, ep_reward: 10.0\n",
      "\n",
      "Episode 13, ep_reward: 8.00\n",
      "\n",
      "Episode 14, ep_reward: 8.0\n",
      "\n",
      "Episode 15, ep_reward: 8.0\n",
      "\n",
      "Episode 16, ep_reward: 9.0\n",
      "\n",
      "Episode 17, ep_reward: 9.00\n",
      "\n",
      "Episode 18, ep_reward: 9.00\n",
      "\n",
      "Episode 19, ep_reward: 9.00\n",
      "\n",
      "Episode 20, ep_reward: 8.00\n",
      "\n",
      "Episode 21, ep_reward: 9.0\n",
      "\n",
      "Episode 22, ep_reward: 10.0\n",
      "\n",
      "Episode 23, ep_reward: 8.00\n",
      "\n",
      "Episode 24, ep_reward: 9.0\n",
      "\n",
      "Episode 25, ep_reward: 10.0\n",
      "\n",
      "Episode 26, ep_reward: 9.00\n",
      "\n",
      "Episode 27, ep_reward: 8.00\n",
      "\n",
      "Episode 28, ep_reward: 9.0\n",
      "\n",
      "Episode 29, ep_reward: 7.00\n",
      "\n",
      "Episode 30, ep_reward: 9.0\n",
      "\n",
      "Episode 31, ep_reward: 9.00\n",
      "\n",
      "Episode 32, ep_reward: 9.00\n",
      "\n",
      "Episode 33, ep_reward: 9.00\n",
      "\n",
      "Episode 34, ep_reward: 8.00\n",
      "\n",
      "Episode 35, ep_reward: 9.0\n",
      "\n",
      "Episode 36, ep_reward: 9.00\n",
      "\n",
      "Episode 37, ep_reward: 7.00\n",
      "\n",
      "Episode 38, ep_reward: 8.0\n",
      "\n",
      "Episode 39, ep_reward: 8.0\n",
      "\n",
      "Episode 40, ep_reward: 8.0\n",
      "\n",
      "Episode 41, ep_reward: 9.0\n",
      "\n",
      "Episode 42, ep_reward: 8.00\n",
      "\n",
      "Episode 43, ep_reward: 9.0\n",
      "\n",
      "Episode 44, ep_reward: 9.00\n",
      "\n",
      "Episode 45, ep_reward: 8.00\n",
      "\n",
      "Episode 46, ep_reward: 9.0\n",
      "\n",
      "Episode 47, ep_reward: 8.00\n",
      "\n",
      "Episode 48, ep_reward: 9.0\n",
      "\n",
      "Episode 49, ep_reward: 8.00\n",
      "\n",
      "Episode 50, ep_reward: 7.0\n",
      "\n",
      "Episode 51, ep_reward: 9.0\n",
      "\n",
      "Episode 52, ep_reward: 9.00\n",
      "\n",
      "Episode 53, ep_reward: 7.00\n",
      "\n",
      "Episode 54, ep_reward: 8.0\n",
      "\n",
      "Episode 55, ep_reward: 8.0\n",
      "\n",
      "Episode 56, ep_reward: 9.0\n",
      "\n",
      "Episode 57, ep_reward: 9.00\n",
      "\n",
      "Episode 58, ep_reward: 9.00\n",
      "\n",
      "Episode 59, ep_reward: 10.0\n",
      "\n",
      "Episode 60, ep_reward: 8.00\n",
      "\n",
      "Episode 61, ep_reward: 8.0\n",
      "\n",
      "Episode 62, ep_reward: 8.0\n",
      "\n",
      "Episode 63, ep_reward: 9.0\n",
      "\n",
      "Episode 64, ep_reward: 8.00\n",
      "\n",
      "Episode 65, ep_reward: 8.0\n",
      "\n",
      "Episode 66, ep_reward: 9.0\n",
      "\n",
      "Episode 67, ep_reward: 9.00\n",
      "\n",
      "Episode 68, ep_reward: 7.00\n",
      "\n",
      "Episode 69, ep_reward: 9.0\n",
      "\n",
      "Episode 70, ep_reward: 8.00\n",
      "\n",
      "Episode 71, ep_reward: 8.0\n",
      "\n",
      "Episode 72, ep_reward: 8.0\n",
      "\n",
      "Episode 73, ep_reward: 9.0\n",
      "\n",
      "Episode 74, ep_reward: 8.00\n",
      "\n",
      "Episode 75, ep_reward: 9.0\n",
      "\n",
      "Episode 76, ep_reward: 8.00\n",
      "\n",
      "Episode 77, ep_reward: 9.0\n",
      "\n",
      "Episode 78, ep_reward: 10.0\n",
      "\n",
      "Episode 79, ep_reward: 9.00\n",
      "\n",
      "Episode 80, ep_reward: 8.00\n",
      "\n",
      "Episode 81, ep_reward: 8.0\n",
      "\n",
      "Episode 82, ep_reward: 8.0\n",
      "\n",
      "Episode 83, ep_reward: 7.0\n",
      "\n",
      "Episode 84, ep_reward: 10.0\n",
      "\n",
      "Episode 85, ep_reward: 9.00\n",
      "\n",
      "Episode 86, ep_reward: 7.00\n",
      "\n",
      "Episode 87, ep_reward: 9.0\n",
      "\n",
      "Episode 88, ep_reward: 8.00\n",
      "\n",
      "Episode 89, ep_reward: 9.0\n",
      "\n",
      "Episode 90, ep_reward: 9.00\n",
      "\n",
      "Episode 91, ep_reward: 7.00\n",
      "\n",
      "Episode 92, ep_reward: 8.0\n",
      "\n",
      "Episode 93, ep_reward: 8.0\n",
      "\n",
      "Episode 94, ep_reward: 8.0\n",
      "\n",
      "Episode 95, ep_reward: 9.0\n",
      "\n",
      "Episode 96, ep_reward: 8.00\n",
      "\n",
      "Episode 97, ep_reward: 9.0\n",
      "\n",
      "Episode 98, ep_reward: 8.00\n",
      "\n",
      "Episode 99, ep_reward: 9.0\n",
      "\n",
      "Episode 100, ep_reward: 9.0\n",
      "\n",
      "Episode 101, ep_reward: 10.0\n",
      "\n",
      "Episode 102, ep_reward: 8.00\n",
      "\n",
      "Episode 103, ep_reward: 8.0\n",
      "\n",
      "Episode 104, ep_reward: 8.0\n",
      "\n",
      "Episode 105, ep_reward: 9.0\n",
      "\n",
      "Episode 106, ep_reward: 9.00\n",
      "\n",
      "Episode 107, ep_reward: 8.00\n",
      "\n",
      "Episode 108, ep_reward: 7.0\n",
      "\n",
      "Episode 109, ep_reward: 8.0\n",
      "\n",
      "Episode 110, ep_reward: 9.0\n",
      "\n",
      "Episode 111, ep_reward: 9.00\n",
      "\n",
      "Episode 112, ep_reward: 10.0\n",
      "\n",
      "Episode 113, ep_reward: 9.00\n",
      "\n",
      "Episode 114, ep_reward: 9.00\n",
      "\n",
      "Episode 115, ep_reward: 9.00\n",
      "\n",
      "Episode 116, ep_reward: 9.00\n",
      "\n",
      "Episode 117, ep_reward: 8.00\n",
      "\n",
      "Episode 118, ep_reward: 9.0\n",
      "\n",
      "Episode 119, ep_reward: 7.00\n",
      "\n",
      "Episode 120, ep_reward: 8.0\n",
      "\n",
      "Episode 121, ep_reward: 8.0\n",
      "\n",
      "Episode 122, ep_reward: 9.0\n",
      "\n",
      "Episode 123, ep_reward: 9.00\n",
      "\n",
      "Episode 124, ep_reward: 10.0\n",
      "\n",
      "Episode 125, ep_reward: 9.00\n",
      "\n",
      "Episode 126, ep_reward: 7.00\n",
      "\n",
      "Episode 127, ep_reward: 8.0\n",
      "\n",
      "Episode 128, ep_reward: 9.0\n",
      "\n",
      "Episode 129, ep_reward: 8.00\n",
      "\n",
      "Episode 130, ep_reward: 8.0\n",
      "\n",
      "Episode 131, ep_reward: 9.0\n",
      "\n",
      "Episode 132, ep_reward: 9.00\n",
      "\n",
      "Episode 133, ep_reward: 9.00\n",
      "\n",
      "Episode 134, ep_reward: 10.0\n",
      "\n",
      "Episode 135, ep_reward: 8.00\n",
      "\n",
      "Episode 136, ep_reward: 7.0\n",
      "\n",
      "Episode 137, ep_reward: 9.0\n",
      "\n",
      "Episode 138, ep_reward: 8.00\n",
      "\n",
      "Episode 139, ep_reward: 8.0\n",
      "\n",
      "Episode 140, ep_reward: 9.0\n",
      "\n",
      "Episode 141, ep_reward: 8.00\n",
      "\n",
      "Episode 142, ep_reward: 8.0\n",
      "\n",
      "Episode 143, ep_reward: 9.0\n",
      "\n",
      "Episode 144, ep_reward: 10.0\n",
      "\n",
      "Episode 145, ep_reward: 8.00\n",
      "\n",
      "Episode 146, ep_reward: 9.0\n",
      "\n",
      "Episode 147, ep_reward: 8.00\n",
      "\n",
      "Episode 148, ep_reward: 9.0\n",
      "\n",
      "Episode 149, ep_reward: 8.00\n",
      "\n",
      "Episode 150, ep_reward: 9.0\n",
      "\n",
      "Episode 151, ep_reward: 8.00\n",
      "\n",
      "Episode 152, ep_reward: 8.0\n",
      "\n",
      "Episode 153, ep_reward: 9.0\n",
      "\n",
      "Episode 154, ep_reward: 8.00\n",
      "\n",
      "Episode 155, ep_reward: 8.0\n",
      "\n",
      "Episode 156, ep_reward: 9.0\n",
      "\n",
      "Episode 157, ep_reward: 8.00\n",
      "\n",
      "Episode 158, ep_reward: 8.0\n",
      "\n",
      "Episode 159, ep_reward: 7.0\n",
      "\n",
      "Episode 160, ep_reward: 8.0\n",
      "\n",
      "Episode 161, ep_reward: 9.0\n",
      "\n",
      "Episode 162, ep_reward: 8.00\n",
      "\n",
      "Episode 163, ep_reward: 8.0\n",
      "\n",
      "Episode 164, ep_reward: 9.0\n",
      "\n",
      "Episode 165, ep_reward: 9.00\n",
      "\n",
      "Episode 166, ep_reward: 9.00\n",
      "\n",
      "Episode 167, ep_reward: 9.00\n",
      "\n",
      "Episode 168, ep_reward: 8.00\n",
      "\n",
      "Episode 169, ep_reward: 7.0\n",
      "\n",
      "Episode 170, ep_reward: 10.0\n",
      "\n",
      "Episode 171, ep_reward: 8.00\n",
      "\n",
      "Episode 172, ep_reward: 8.0\n",
      "\n",
      "Episode 173, ep_reward: 8.0\n",
      "\n",
      "Episode 174, ep_reward: 9.0\n",
      "\n",
      "Episode 175, ep_reward: 8.00\n",
      "\n",
      "Episode 176, ep_reward: 8.0\n",
      "\n",
      "Episode 177, ep_reward: 8.0\n",
      "\n",
      "Episode 178, ep_reward: 8.0\n",
      "\n",
      "Episode 179, ep_reward: 9.0\n",
      "\n",
      "Episode 180, ep_reward: 8.00\n",
      "\n",
      "Episode 181, ep_reward: 8.0\n",
      "\n",
      "Episode 182, ep_reward: 9.0\n",
      "\n",
      "Episode 183, ep_reward: 8.00\n",
      "\n",
      "Episode 184, ep_reward: 9.0\n",
      "\n",
      "Episode 185, ep_reward: 8.00\n",
      "\n",
      "Episode 186, ep_reward: 9.0\n",
      "\n",
      "Episode 187, ep_reward: 8.00\n",
      "\n",
      "Episode 188, ep_reward: 9.0\n",
      "\n",
      "Episode 189, ep_reward: 9.00\n",
      "\n",
      "Episode 190, ep_reward: 8.00\n",
      "\n",
      "Episode 191, ep_reward: 9.0\n",
      "\n",
      "Episode 192, ep_reward: 8.00\n",
      "\n",
      "Episode 193, ep_reward: 9.0\n",
      "\n",
      "Episode 194, ep_reward: 9.00\n",
      "\n",
      "Episode 195, ep_reward: 8.00\n",
      "\n",
      "Episode 196, ep_reward: 9.0\n",
      "\n",
      "Episode 197, ep_reward: 9.00\n",
      "\n",
      "Episode 198, ep_reward: 8.00\n",
      "\n",
      "Episode 199, ep_reward: 8.0\n",
      "\n",
      "Episode 199, ep_reward: 9.0\r"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"CartPole-v1\")\n",
    "agent = Agent(env.action_space.n)\n",
    "num_episodes = 200\n",
    "train(agent, env, num_episodes, render=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c398c9f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12",
   "language": "python",
   "name": "python3812jvsc74a57bd0f14269bf3ad7aa2ae115b9ca9481e15e8eacecd83dc3347ac1efd388ad78cc6e"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
